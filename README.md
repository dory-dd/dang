# プロジェクト概要

プロジェクトのポリシーと、運用の変遷なンダ。現在は使われてないものがたくさんあるンダ

### オリジナルのポリシー

このプロジェクトは、WEBアプリで公開することを目指して作成していたンダ。アプリの動的なグラフ生成に柔軟に対応するため、以下を心がけたンダッチ。

#### 設計

- **WEBアプリを目指して作成**: プロジェクトのゴールは、WEBアプリケーションとして実装することンダ。ユーザーが簡単に操作できるようなインターフェースを提供して、掲示板のデータを視覚的に見せることが目的ダッチ。

- **基本情報はtable、分析はviewで処理**: データベースの設計では、基本的な情報はテーブルで管理し、より複雑な分析や統計処理はビューを使って行っているンダ。そうすることで、データの整合性を保ちつつ、効率的にデータを処理できるようにしているダッチ。

#### 運用

- **flaskでブラウザからグラフを動的に生成**: プロジェクトでは、Flaskを使ってブラウザからグラフをダイナミックに生成しているンダ。だから、ユーザーはリアルタイムにデータの分析結果を見ることができたダッチ。

- **30分に1回、現行のスレからcronでスクレイピング**: 掲示板からのデータ収集はcronジョブを使って定期的に行っていたンダ。30分ごとに最新のスレッドからデータをスクレイピングして、データベースをアップデートしていたンダッチ。

- **パースは変更せず、例外処理でエラーレコードに保存**: データのパースは3chan時代から変わってないンダ。エラーが起きた場合はエラーレコードに保存して、統計処理の対象外にしていたんダッチ。

### 運用の変遷

- **少し前の運用**: 過去ログを収集するようにした。過去ログの収集は、`cronning_board.py`スクリプトを使って定期的に行っていたンダ。

- **現在の運用**: 現在はJupyter Notebook (`notebook/`)を使って都度のデータ収集と分析を行っているンダ。掲示板の最新情報を取得し、データベースに保存するために、ノートブック内でスクレイピングとデータ処理をしているンダッチ。

このプロジェクトは、WEBアプリケーションの構築を目指して、定期的なデータ収集と統計的な分析を組み合わせて掲示板の情報を視覚化しているンダ。さまざまな運用方法の変遷を経て、柔軟で効率的なデータ解析環境を整えているンダッチ。
たぶん新規性があるのは「判例集検証」だけだと思う

このプロジェクトは、sannan.nl掲示板からのデータスクレイピングと収集、統計的分析を目的としています。掲示板の議論に関する傾向やパターンを把握することを目指しています。プロジェクトには、データ収集、データベース操作、分析、および自動化に関する複数のPythonスクリプトが含まれています。

### プロジェクトの詳細構成

1. `scraper.py`: sannan.nl掲示板からスレッド情報や内容を抽出するためのPythonスクリプトです。URLからデータを取得し、必要な情報をパースするための関数を提供します。

2. `db_thread_detail_data.py`: このスクリプトはSQLiteデータベース操作を担当し、SQLクエリの実行、データのテーブルへの挿入、テーブルやビューの作成を行います。データベースとのスムーズなやり取りを保証します。

3. `db_handler.py`: このスクリプトはSQLiteデータベースを操作し、`trans_unixtime_to_datestr`、`create_database`、`save_data`、`load_data`などの関数を含みます。これらの関数はデータのデータベースへの保存と取得を支援します。

4. `analize_thread.py`: このスクリプトは統計的分析に特化しています。`count_sections`、`calc_similarity`、`make_3ch_urls`などの関数を含み、データに対して様々な分析を行います。

5. `db_create_analyze_view.py`: このスクリプトはデータベースにビューを作成するためのもので、`create_views`関数を使用してデイリーコメント数、時間ごとのコメント数、一意のID割合などのビューを作成します。

6. `helper.py`: このスクリプトには、他のスクリプトで使用される便利な関数が含まれています。`sum_res_numbers_from_url`、`measure_time`、`get_max_res_num`など、データ処理や計算をサポートする関数です。

7. `cronning_board.py`: このスクリプトは掲示板からスレッド情報を定期的にスクレイピングしてデータベースに保存する自動化タスクを実行します。`scraper_main`関数を使用してスクレイピングプロセスを制御します。

### optional
## view/index.py 概要

`view/index.py`は、Streamlitを使用して可視化を行うPythonスクリプトです。このスクリプトは、プロジェクトの他の部分で収集されたデータを取得し、グラフを生成して表示します。主に以下の機能が含まれています：

1. `count_posts_with_isolation_rate`: 書き込み回数と単発ID率の関係をグラフ化して表示します。SQLiteデータベースから必要なデータを取得し、MatplotlibとSeabornを使用してグラフを描画します。グラフには、日付ごとの書き込み回数を棒グラフとして表示し、単発ID率を折れ線グラフとして表示しています。

2. `plot_carrier_percentage`: キャリアごとの書き込み率をグラフ化して表示します。SQLiteデータベースから必要なデータを取得し、MatplotlibとSeabornを使用して折れ線グラフを描画します。キャリアごとの書き込み率の変化を時系列で確認できます。

3. `plot_histogram`: ID別書き込み回数のヒストグラムを描画して表示します。SQLiteデータベースから必要なデータを取得し、MatplotlibとSeabornを使用して対数軸のKDEプロットを作成します。グラフには、書き込み回数の分布や平均、中央値、標準偏差が表示されます。

4. `plot_hourly_comment_counts`: 時間別のコメント数の推移をグラフ化して表示します。SQLiteデータベースから必要なデータを取得し、MatplotlibとSeabornを使用して棒グラフと折れ線グラフを作成します。時間ごとのコメント数の変化や移動平均が可視化されます。

5. `show_data`: 上記の関数を呼び出して、複数のグラフを1つのStreamlitアプリケーションに表示します。書き込み回数と単発ID率のグラフ、キャリア別の書き込み率のグラフ、時間別のコメント数のグラフが一括して表示されます。

6. `main`: Streamlitアプリケーションのメイン関数であり、`show_data`関数を呼び出してグラフを表示します。アプリケーションのタイトルを設定しています。

## notebook/ 概要
最近はもっぱらここで作業してた。
